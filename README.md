# ğŸ”¢ Improving Visual Numerosity in Multimodal Models (LLaVA)

## ğŸ” Key Engineering Problem

The Multimodal Large Language Models (MMLLMs) 
![Results](Readme%20Figures/llava_architecture.png)
## ğŸ“Š Datasets

![Results](Readme%20Figures/ccnl1_dataset_illustration.png)
![Results](Readme%20Figures/ccnl2_obj_num_pairs.png)
![Results](Readme%20Figures/clevr_dataset_illustration.png)


## ğŸ“‰ Baseline Results (Untuned LLaVA)

## ğŸ”§ Fine-Tuning Approaches
- Multimodal Projector:
- Vision Transformer (ViT):
- Projector + ViT:
  
- Language Model Ablations
- Learning Rate Ablations: 

## ğŸ”„ Generalization & Transfer Experiments

In this work, I have conducted experiments to see how the performance improvement in enumeration transfers. The following transfer scenarious were considered:

- Cross-category transfer
- Even â†’ Odd numerosity transfer
- Cross Dataset Transfer (CCNL2 to CCNL1)
  
## ğŸ§© Representation Analysis
- Few-shot linear probing
- PCA embedding analysis

## ğŸ“ Hyperparameter Analysis

## ğŸ” Transfer to Downstream Numerical Tasks

## ğŸ“Œ Key Improvements and Discussion

## âš ï¸ Limitations and Future Work


## ğŸ“„ Thesis Reference


## ğŸ™ Acknowledgements
