{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPCGgwXQ6F756xqxyhbvq50"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8_gz3A_9-ByO"},"outputs":[],"source":["import os\n","import random\n","\n","import torch\n","from torch.utils.data import Dataset\n","\n","from PIL import Image\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"]},{"cell_type":"code","source":["class NumerosityDataset(Dataset):\n","    def __init__(\n","        self,\n","        image_folder,\n","        tokenizer,\n","        allowed_objects=None,\n","        allowed_numerosities=None,\n","        undersample_fraction=1.0,\n","        seed=None\n","    ):\n","        self.data = []\n","        self.tokenizer = tokenizer\n","\n","        # Sorted list ensures reproducibility across platforms\n","        images = sorted([f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))])\n","\n","        for img_name in images:\n","            parts = img_name.split('_')\n","            if len(parts) < 2:\n","                continue\n","\n","            try:\n","                numerosity = int(parts[0])\n","            except ValueError:\n","                continue\n","\n","            object_type = parts[1].lower()\n","\n","            # Filtering\n","            if allowed_numerosities is not None and numerosity not in allowed_numerosities:\n","                continue\n","            if allowed_objects is not None and object_type not in allowed_objects:\n","                continue\n","\n","            self.data.append({\n","                \"image_path\": os.path.join(image_folder, img_name),\n","                \"numerosity\": numerosity,\n","                \"object_type\": object_type\n","            })\n","\n","        # Apply undersampling if requested\n","        if 0 < undersample_fraction < 1.0:\n","            if seed is not None:\n","                random.seed(seed)\n","            sample_size = int(len(self.data) * undersample_fraction)\n","            self.data = random.sample(self.data, sample_size)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","\n","        image_PIL = Image.open(item[\"image_path\"]).convert(\"RGB\")\n","        image_token = \"<image>\"\n","        prompt = f\"USER: {image_token * 576}\\nHow many things are in this image? Answer only with a number without spacing.\\nASSISTANT:\"\n","        text_inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=\"max_length\")\n","\n","        label_tensor = torch.tensor(item[\"numerosity\"], dtype=torch.float)\n","\n","        return {\n","            \"input_ids\": text_inputs[\"input_ids\"].squeeze(0),\n","            \"PIL_images\": image_PIL,\n","            \"labels\": label_tensor,\n","            \"object_type\": item[\"object_type\"]\n","        }\n"],"metadata":{"id":"s7qLYKJR-Mgk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fix_model_dtype(model, device):\n","\n","    print(\"Converting model to float32...\")\n","\n","    # Move to CPU first, convert to float32, then move to device\n","    model = model.cpu().float().to(device)\n","\n","    # Verify all parameters are float32\n","    for name, param in model.named_parameters():\n","        print(f\"Parameter {name}: {param.dtype}\")\n","        if param.dtype != torch.float32:\n","            param.data = param.data.float()\n","            print(f\"  -> Converted to {param.dtype}\")\n","\n","    # Verify all buffers are float32 too\n","    for name, buffer in model.named_buffers():\n","        print(f\"Buffer {name}: {buffer.dtype}\")\n","        if buffer.dtype != torch.float32:\n","            buffer.data = buffer.data.float()\n","            print(f\"  -> Converted to {buffer.dtype}\")\n","\n","    return model"],"metadata":{"id":"hGqRWYkMCP_K"},"execution_count":null,"outputs":[]}]}